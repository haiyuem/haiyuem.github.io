<!DOCTYPE html>
<html>
<head>
    <title>Haiyue Ma - Ph.D. Student @ Princeton</title>
    <style>
        body {
            font-family: 'Arial', sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f3f3f3;
            color: #333333;
        }
        header, footer {
            background-color: #333333;
            color: white;
            text-align: center;
            padding: 1em 0;
        }
        .container {
            width: 80%;
            margin: auto;
            overflow: hidden;
        }
        nav {
            background: #444444;
            color: white;
            text-align: center;
            padding: 1em 0;
        }
        nav a {
            color: white;
            margin: 0 15px;
            text-decoration: none;
            font-weight: bold;
        }
        .section {
            margin: 4em 0;
        }
        .section h2 {
            color: #333333;
        }
        .publications li {
            margin-bottom: 0.5em;
        }
        .about-section {
            display: flex;
            align-items: center;
            justify-content: center;
        }
        .about-text {
            flex: 1;
            padding: 15px;
        }
        header {
            display: flex;
            align-items: center;
            justify-content: center;
            /* Add additional styling as needed */
        }
        .header-text {
            margin-left: 20px; /* Adjust spacing as needed */
        }
        .header-photo img {
            max-width: 100px; /* Adjust size as needed */
            height: auto;
            border-radius: 50%; /* Optional: for a circular photo */
        }
    </style>
</head>
<body>

<header>
    <div class="header-photo">
        <!-- Replace 'path_to_your_photo.jpg' with the actual path to your photo -->
        <img src="headshot.jpg" alt="Your Name">
    </div>
    <div class="header-text">
        <h1>Haiyue Ma</h1>
        <p>Ph.D. Student in Computer Architecture</p>
    </div>
</header>

<nav>
    <a href="#about">About</a>
    <a href="#research">Research</a>
    <!-- <a href="#publications">Publications</a> -->
    <a href="#CV">CV</a>
    <a href="#contact">Contact</a>
    <a href="#blog">Crazy Ideas</a> <!-- New Blog Link -->
</nav>

<div class="container">
    <section id="about" class="section">
        <h2>About Me</h2>
        <p>I am an Electrical and Computer Engineering Ph.D. candidate at Princeton University, doing research in Computer Architecture.</p>
        <p>I am a member of the <a href="https://parallel.princeton.edu/" target="_blank">Princeton Parallel Group</a>, advised by Prof. David Wentzlaff.</p>
        <p>Before joining Princeton, I spent three years at Nvidia, working on architecture explorations for future GPU designs with a focus on DL workloads, and full-chip GPU power analysis. I graduated from Washington University in St. Louis with a B.S. in Electrical Engineering in 2018.</p>

    </section>

    <section id="research" class="section">
        <h2>Research</h2>
        I am broadly interested in hardware/software co-design and system-level performance optimization for emerging workloads. My main research direction is on scheduling. 
        <!-- My current and past research directions include: 
        <ul class="research interests">
            <li>System-level AI safety precautions </li>
            <li>Compute unit interconnections and communication patterns</li>
            <li>Data movement patterns and dataflow architecture</li>
            <li>Scheduling policies and strategies </li>
        </ul>    </p> -->

        My past and current work include:
        <ul class="llm scheduling">
        LLM scheduling: Hardware-aware scheduling for large-scale LLM workloads to improve efficiency 
        <li><strong>Reducing the Cost of Dropout in Flash-Attention by Hiding RNG with GEMM</strong>
            <em>In Submission</em>
            In LLM training, fusing Dropout into Flash-Attention causes hardware resource contention and GPU underutilization. We propose overlapping RNG (the major part of Dropout) with GEMM to improve training efficiency since they have complementary resource utilization and no data dependency.
        
        <li><strong>Data-aware MoE Scheduling: Predicting and Balancing Expert Distribution for LLM Serving </strong>
            <em>Work in Progress</em>
            Expert Parallelism ideally performs better than Tensor Parallelism with uniform expert distribution; however real workloads have heavily skewed distributions which leads to load imbalance and bubbles. We attempt to predict and re-distributes experts to achieve near-optimal performance with Expert Parallelism for LLM serving.
            
        <li><strong>A Fine-Grained Theoretical Model for LLM Scheduler Exploration: Fusion and Overlapping </strong>
            <em>Work in Progress</em>
            A fast, first-principle model based on GPU resource utilization to analyze the performance of different LLM scheduling strategies, including fusion and overlapping.
        </ul>
        
        <ul class="inst level scheduling">
        Data-aware Instruction-level scheduling 
        <li><strong>A Value-Aware, Dynamic Hardware Scheduler for Energy Reduction</strong>
            <em>In Submission</em>
            A hardware scheduler added to the Issue Stage of the pipeline that predicts instruction operand value locality and schedules instructions with similar operands consecutively to reduce switching activity and dynamic energy consumption.
        <li><strong>DVProf: Profiling Dynamic Value Locality Between Instructions</strong> (Poster) <br></li>
            <em>2024 IEEE International Symposium on Workload Characterization Posters</em>, Vancouver, Canada
        <li><strong>Exploiting Data Commonality in Value Prediction</strong> (Workshop paper) <br></li>
            <em>The Fifth Young Architect Workshop at ASPLOS 2023</em>, Vancouver, Canada
        </ul>
    </section>

    <!-- <section id="publications" class="section">
        <h2>Publications</h2>
        <ul class="publications">
            <li><strong>Exploiting Data Commonality in Value Prediction</strong> (Workshop paper) <br></li>
            <em>The Fifth Young Architect Workshop at ASPLOS 2023</em>, Vancouver, Canada
        </ul>
    </section> -->

    <section id="cv" class="section">
        <h2>CV</h2>
        <p>You can download my CV <a href="CV_Haiyue_Ma.pdf" download>here</a>.</p>
    </section>

    <section id="blog" class="section">
        <h2>Blog Articles on Crazy Ideas</h2>
        <ul>
            <li><a href="ai_safety_blog.html">A Hardware "Stop Button" for AI Applications</a> - March 2024</li>
            <!-- Add more blog posts here -->
        </ul>
    </section>

    <section id="contact" class="section">
        <h2>Contact</h2>
        <p> Email: hm1@princeton.edu </p>
        <p> LinkedIn: <a href="https://www.linkedin.com/in/haiyue-ma/" target="_blank">My LinkedIn Profile</a> </p>
    </section>
</div>

<footer>
    <p> Haiyue Ma - Last Updated Sep. 2024</p>
</footer>

</body>
</html>
